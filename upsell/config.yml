env:
  cuda: True
  seed: 42

preprocessing:
  seed: 42
  sampling:  # These configs result in a maximum sample size of 102,000 accounts
    # TODO: min_positives required to train a model
    max_positives: 6000
    neg_w_activity_prop: 8
    neg_w_intent_prop: 4
    neg_w_none_prop: 4
  firmo_rollup:
    top_n_categories: 5
  activity_rollup:
    min_occurrences: 150
    min_accounts: 75
  train_size: 0.8

data_loader:
  train_validation_split: 0.85
  bucket_seqs: True
  batch_size:
    min_pow_2: 5  # 32
    max_pow_2: 8  # 256
    default: 64
  attr_batch_size: 8
  num_workers: 0

model:
  embedding_dim:  # length of embeddings at each time step
    min_pow_2: 4  # 16
    max_pow_2: 8  # 256
    default: 64
  hidden_size:  # length of full embedding history
    min_pow_2: 5  # 32
    max_pow_2: 9  # 512
    default: 128
  rnn: 'GRU'
  dropout:
    min: 0.0
    max: 0.2
    default: 0.0
  basis_type: 'means'
  basis_means:
    - 0
    - 1
    - 2
    - 4
    - 6
    - 8
    - 12
    - 25
    - 52
  max_log_basis_weight: 10
  ks:
    - 0.001
    - 0.01
    - 0.1
    - 0.5
    - 1.0
    - 2.0

train:
  optimizer: 'Adam'
  lr:
    min: 1.e-5
    max: 1.e-1
    default: 1.e-3
  epochs: 150
  l2_reg: 0
  tune_metric: 'nll'
  patience: 3

tuning:
  max_training_iterations: 150  # max number of epochs to train any model
  grace_period: 1  # min number of epochs to train any model
  reduction_factor: 2  # 1/factor = proportion of models to keep after each round
  n_param_combos: 30

attribution:
  skip_eval_infectivity: True
  steps: 50
  occurred_type_only: True

predict:
  min_time_steps: 1
  max_time_steps: 5
